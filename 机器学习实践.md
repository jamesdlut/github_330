---
typora-copy-images-to: ../../Pictures/Jie_Tu_NEVER_CHANGE_NAME_lOCATION
---

##### stacking 

###### 原理

https://zhuanlan.zhihu.com/p/26890738?utm_medium=social&utm_source=qq

这个文章看起来比较通俗

对于每个数据来说，每个模型的作用就是产生一个特征

下一行绿色的测试集，就是按照相同的套路，把测试集的特征也转化，变为我需要的测试集！

![1517043602090](/home/wangchen/Pictures/Jie_Tu_NEVER_CHANGE_NAME_lOCATION/1517043602090.png)



![1517033863920](/home/wangchen/Pictures/Jie_Tu_NEVER_CHANGE_NAME_lOCATION/1517033863920.png)

###### 固定k-fold　否则有过拟合风险

![1517045512847](/home/wangchen/Pictures/Jie_Tu_NEVER_CHANGE_NAME_lOCATION/1517045512847.png)

https://www.zhihu.com/question/61467937/answer/188191424

看懂这个图，

stage1:k折　m1 m2实际上是模型训练后，由x1,x2得到的特征（其实就是model 1的预测），隐含着信息！

stage2:没有k折！是留一法



![1517045203019](/home/wangchen/Pictures/Jie_Tu_NEVER_CHANGE_NAME_lOCATION/1517045203019.png)

![1517045440237](/home/wangchen/Pictures/Jie_Tu_NEVER_CHANGE_NAME_lOCATION/1517045440237.png)



标签泄漏(Label Leak)**

![1517033901427](/home/wangchen/Pictures/Jie_Tu_NEVER_CHANGE_NAME_lOCATION/1517033901427.png)



##### XGboost和LightGBM

##### [Hyperopt](https://link.zhihu.com/?target=https%3A//github.com/hyperopt/hyperopt) | 通用的优化框架，可用于调参



 